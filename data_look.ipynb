{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data examination\n",
    "Questions:\n",
    "* 1. how many words are there in each subcorpus? (single words vs mwe / bible vs biomed vs europarl)\n",
    "* 2. are there multiple target word instances in a sentence?\n",
    "* 3. are there any words not in BERT vocab? (are there words that are segmented futher?)\n",
    "* 4. are there any oov subwords in oov words?\n",
    "\n",
    "SUMMARY:\n",
    "* case is important to identify target token position in a sentence\n",
    "* not all tokens are present in BERT vocabulary (should they be represented as an average of their subwords?)\n",
    "* cased BERT has less unsegmented tokens than uncased (case can be used to id target word in a sentence, but then lowercased and represented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tsv(file_name):\n",
    "    df = pd.read_csv(file_name, '\\t', quoting=3, na_filter=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_train = read_tsv('data/train/lcp_single_train.tsv')\n",
    "multi_train = read_tsv('data/train/lcp_multi_train.tsv')\n",
    "\n",
    "single_trial = read_tsv('data/trial/lcp_single_trial.tsv')\n",
    "multi_trial = read_tsv('data/trial/lcp_multi_trial.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>corpus</th>\n",
       "      <th>sentence</th>\n",
       "      <th>token</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3ZLW647WALVGE8EBR50EGUBPU4P32A</td>\n",
       "      <td>bible</td>\n",
       "      <td>Behold, there came up out of the river seven c...</td>\n",
       "      <td>river</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34R0BODSP1ZBN3DVY8J8XSIY551E5C</td>\n",
       "      <td>bible</td>\n",
       "      <td>I am a fellow bondservant with you and with yo...</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3S1WOPCJFGTJU2SGNAN2Y213N6WJE3</td>\n",
       "      <td>bible</td>\n",
       "      <td>The man, the lord of the land, said to us, 'By...</td>\n",
       "      <td>brothers</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id corpus  \\\n",
       "0  3ZLW647WALVGE8EBR50EGUBPU4P32A  bible   \n",
       "1  34R0BODSP1ZBN3DVY8J8XSIY551E5C  bible   \n",
       "2  3S1WOPCJFGTJU2SGNAN2Y213N6WJE3  bible   \n",
       "\n",
       "                                            sentence     token  complexity  \n",
       "0  Behold, there came up out of the river seven c...     river        0.00  \n",
       "1  I am a fellow bondservant with you and with yo...  brothers        0.00  \n",
       "2  The man, the lord of the land, said to us, 'By...  brothers        0.05  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>corpus</th>\n",
       "      <th>sentence</th>\n",
       "      <th>token</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3S37Y8CWI80N8KVM53U4E6JKCDC4WE</td>\n",
       "      <td>bible</td>\n",
       "      <td>but the seventh day is a Sabbath to Yahweh you...</td>\n",
       "      <td>seventh day</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3WGCNLZJKF877FYC1Q6COKNWTDWD11</td>\n",
       "      <td>bible</td>\n",
       "      <td>But let each man test his own work, and then h...</td>\n",
       "      <td>own work</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3UOMW19E6D6WQ5TH2HDD74IVKTP5CB</td>\n",
       "      <td>bible</td>\n",
       "      <td>To him who by understanding made the heavens; ...</td>\n",
       "      <td>loving kindness</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id corpus  \\\n",
       "0  3S37Y8CWI80N8KVM53U4E6JKCDC4WE  bible   \n",
       "1  3WGCNLZJKF877FYC1Q6COKNWTDWD11  bible   \n",
       "2  3UOMW19E6D6WQ5TH2HDD74IVKTP5CB  bible   \n",
       "\n",
       "                                            sentence            token  \\\n",
       "0  but the seventh day is a Sabbath to Yahweh you...      seventh day   \n",
       "1  But let each man test his own work, and then h...         own work   \n",
       "2  To him who by understanding made the heavens; ...  loving kindness   \n",
       "\n",
       "   complexity  \n",
       "0    0.027778  \n",
       "1    0.050000  \n",
       "2    0.050000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subcorpus</th>\n",
       "      <th>sentence</th>\n",
       "      <th>token</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3QI9WAYOGQB8GQIR4MDIEF0D2RLS67</td>\n",
       "      <td>bible</td>\n",
       "      <td>They will not hurt nor destroy in all my holy ...</td>\n",
       "      <td>sea</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3T8DUCXY0N6WD9X4RTLK8UN1U929TF</td>\n",
       "      <td>bible</td>\n",
       "      <td>that sends ambassadors by the sea, even in ves...</td>\n",
       "      <td>sea</td>\n",
       "      <td>0.102941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3I7KR83SNADXAQ7HXK7S7305BYB9KD</td>\n",
       "      <td>bible</td>\n",
       "      <td>and they entered into the boat, and were going...</td>\n",
       "      <td>sea</td>\n",
       "      <td>0.109375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id subcorpus  \\\n",
       "0  3QI9WAYOGQB8GQIR4MDIEF0D2RLS67     bible   \n",
       "1  3T8DUCXY0N6WD9X4RTLK8UN1U929TF     bible   \n",
       "2  3I7KR83SNADXAQ7HXK7S7305BYB9KD     bible   \n",
       "\n",
       "                                            sentence token  complexity  \n",
       "0  They will not hurt nor destroy in all my holy ...   sea    0.000000  \n",
       "1  that sends ambassadors by the sea, even in ves...   sea    0.102941  \n",
       "2  and they entered into the boat, and were going...   sea    0.109375  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_trial.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subcorpus</th>\n",
       "      <th>sentence</th>\n",
       "      <th>token</th>\n",
       "      <th>complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31HLTCK4BLVQ5BO1AUR91TX9V9IVGH</td>\n",
       "      <td>bible</td>\n",
       "      <td>The name of one son was Gershom, for Moses sai...</td>\n",
       "      <td>foreign land</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>389A2A304OIXVY7G5B71Q9M43LE0CL</td>\n",
       "      <td>bible</td>\n",
       "      <td>unleavened bread, unleavened cakes mixed with ...</td>\n",
       "      <td>wheat flour</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31N9JPQXIPIRX2A3S9N0CCFXO6TNHR</td>\n",
       "      <td>bible</td>\n",
       "      <td>However the high places were not taken away; t...</td>\n",
       "      <td>burnt incense</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id subcorpus  \\\n",
       "0  31HLTCK4BLVQ5BO1AUR91TX9V9IVGH     bible   \n",
       "1  389A2A304OIXVY7G5B71Q9M43LE0CL     bible   \n",
       "2  31N9JPQXIPIRX2A3S9N0CCFXO6TNHR     bible   \n",
       "\n",
       "                                            sentence          token  \\\n",
       "0  The name of one son was Gershom, for Moses sai...   foreign land   \n",
       "1  unleavened bread, unleavened cakes mixed with ...    wheat flour   \n",
       "2  However the high places were not taken away; t...  burnt incense   \n",
       "\n",
       "   complexity  \n",
       "0    0.000000  \n",
       "1    0.157895  \n",
       "2    0.200000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_trial.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_trial = single_trial.rename(columns={'subcorpus':'corpus'})\n",
    "multi_trial = multi_trial.rename(columns={'subcorpus':'corpus'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "## how many words are there in each subcorpus? (single words vs mwe / bible vs biomed vs europarl)\n",
    "NOTE: there can be several sentence for the same target word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [single_train, multi_train, single_trial, multi_trial]\n",
    "names = ['single_train', 'multi_train', 'single_trial', 'multi_trial']\n",
    "bible = []\n",
    "europarl = []\n",
    "biomed = []\n",
    "total = []\n",
    "for df in dfs:\n",
    "    bible.append(len(df[df['corpus'] == 'bible']))\n",
    "    europarl.append(len(df[df['corpus'] == 'europarl']))\n",
    "    biomed.append(len(df[df['corpus'] == 'biomed']))\n",
    "    total.append(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATA_NAME</th>\n",
       "      <th>BIBLE_LEN</th>\n",
       "      <th>EUROPARL_LEN</th>\n",
       "      <th>BIOMED_LEN</th>\n",
       "      <th>TOTAL_LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>single_train</td>\n",
       "      <td>2574</td>\n",
       "      <td>2512</td>\n",
       "      <td>2576</td>\n",
       "      <td>7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>multi_train</td>\n",
       "      <td>505</td>\n",
       "      <td>498</td>\n",
       "      <td>514</td>\n",
       "      <td>1517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>single_trial</td>\n",
       "      <td>143</td>\n",
       "      <td>143</td>\n",
       "      <td>135</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi_trial</td>\n",
       "      <td>29</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DATA_NAME  BIBLE_LEN  EUROPARL_LEN  BIOMED_LEN  TOTAL_LEN\n",
       "0  single_train       2574          2512        2576       7662\n",
       "1   multi_train        505           498         514       1517\n",
       "2  single_trial        143           143         135        421\n",
       "3   multi_trial         29            37          33         99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'DATA_NAME':names,'BIBLE_LEN':bible,'EUROPARL_LEN':europarl,'BIOMED_LEN':biomed,'TOTAL_LEN':total}\n",
    "corpora_lens = pd.DataFrame(data)\n",
    "corpora_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "## are there multiple target word instances in a sentence? (Yes and No)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single words\n",
    "### train\n",
    "* when uncased there might be 1/2/3/4/11/9/5 occurances of a token substring in a sentence string (no specific tokenization). there are 87 sentence with multiple target token this way. For example, in sentence 6756, it is not really clear which instance of a target word should be evaluated.\n",
    "* when cased, there are 1/2 occurances of a token substring in a sentence string. only two sentences contain more than 1 occurance.\n",
    "\n",
    "Summary: casing is important for chosing the right target token in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_train['occurance_number_uncased'] = single_train.apply(lambda row:\n",
    "    row['sentence'].lower().count(row['token'].lower()), axis=1\n",
    ")\n",
    "\n",
    "single_train['occurance_number_cased'] = single_train.apply(lambda row:\n",
    "    row['sentence'].count(row['token']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4 11  9  5]\n",
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "print(single_train['occurance_number_uncased'].unique())\n",
    "print(single_train['occurance_number_cased'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(single_train[single_train['occurance_number_uncased']>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>corpus</th>\n",
       "      <th>sentence</th>\n",
       "      <th>token</th>\n",
       "      <th>complexity</th>\n",
       "      <th>occurance_number_uncased</th>\n",
       "      <th>occurance_number_cased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4203</th>\n",
       "      <td>3X4Q1O9UBHMCMY43GF110OQ80EE7O2</td>\n",
       "      <td>biomed</td>\n",
       "      <td>CorA, B, C and D belong to a protein family in...</td>\n",
       "      <td>B</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4814</th>\n",
       "      <td>3A3KKYU7P3H3CAKSB7U0000KY4FWMJ</td>\n",
       "      <td>biomed</td>\n",
       "      <td>The mice used in the present study, (NFR/N × B...</td>\n",
       "      <td>MA</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4927</th>\n",
       "      <td>3T5ZXGO9DEOYRKNPENLOGDE7P89QZL</td>\n",
       "      <td>biomed</td>\n",
       "      <td>Because synapsis occurs in TRIP13-deficient sp...</td>\n",
       "      <td>CO</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5079</th>\n",
       "      <td>3538U0YQ1FU0F2QNF0FL0D5E3B1F3J</td>\n",
       "      <td>biomed</td>\n",
       "      <td>Superficial and deep anterior cortical stainin...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.602941</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5080</th>\n",
       "      <td>3TTPFEFXCTKJQH4BTS1JA1TBTGIH6P</td>\n",
       "      <td>biomed</td>\n",
       "      <td>Peptide Aβ is released from APP by the action ...</td>\n",
       "      <td>N</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7579</th>\n",
       "      <td>36MUZ9VAE626RGSODE1RV46QINFED2</td>\n",
       "      <td>europarl</td>\n",
       "      <td>A4-0124/97 by Mr Wynn, on behalf of the Commit...</td>\n",
       "      <td>VI</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id    corpus  \\\n",
       "4203  3X4Q1O9UBHMCMY43GF110OQ80EE7O2    biomed   \n",
       "4814  3A3KKYU7P3H3CAKSB7U0000KY4FWMJ    biomed   \n",
       "4927  3T5ZXGO9DEOYRKNPENLOGDE7P89QZL    biomed   \n",
       "5079  3538U0YQ1FU0F2QNF0FL0D5E3B1F3J    biomed   \n",
       "5080  3TTPFEFXCTKJQH4BTS1JA1TBTGIH6P    biomed   \n",
       "7579  36MUZ9VAE626RGSODE1RV46QINFED2  europarl   \n",
       "\n",
       "                                               sentence token  complexity  \\\n",
       "4203  CorA, B, C and D belong to a protein family in...     B    0.400000   \n",
       "4814  The mice used in the present study, (NFR/N × B...    MA    0.593750   \n",
       "4927  Because synapsis occurs in TRIP13-deficient sp...    CO    0.526316   \n",
       "5079  Superficial and deep anterior cortical stainin...     N    0.602941   \n",
       "5080  Peptide Aβ is released from APP by the action ...     N    0.750000   \n",
       "7579  A4-0124/97 by Mr Wynn, on behalf of the Commit...    VI    0.485294   \n",
       "\n",
       "      occurance_number_uncased  occurance_number_cased  \n",
       "4203                         4                       1  \n",
       "4814                         4                       1  \n",
       "4927                         4                       1  \n",
       "5079                        11                       1  \n",
       "5080                         9                       1  \n",
       "7579                         5                       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_train[single_train['occurance_number_uncased']>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approval of the minutes of the previous sitting: see minutes\n",
      "Approval of Minutes of previous sitting: see Minutes\n"
     ]
    }
   ],
   "source": [
    "for s in single_train[single_train['occurance_number_cased']>1]['sentence']:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single words\n",
    "### trial\n",
    "* only 1 target occuarnce for cased\n",
    "* 6 sentences with 2 occurances for uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_trial['occurance_number_uncased'] = single_trial.apply(lambda row:\n",
    "    row['sentence'].lower().count(row['token'].lower()), axis=1\n",
    ")\n",
    "\n",
    "single_trial['occurance_number_cased'] = single_trial.apply(lambda row:\n",
    "    row['sentence'].count(row['token']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(single_trial['occurance_number_uncased'].unique())\n",
    "print(single_trial['occurance_number_cased'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>corpus</th>\n",
       "      <th>sentence</th>\n",
       "      <th>token</th>\n",
       "      <th>complexity</th>\n",
       "      <th>occurance_number_uncased</th>\n",
       "      <th>occurance_number_cased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>3EFNPKWBMSO9IYBXCIW0X6IAX8E030</td>\n",
       "      <td>biomed</td>\n",
       "      <td>Lung development in Dhcr7-/- embryos at the ea...</td>\n",
       "      <td>Lung</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>379OL9DBSSESUVWY1Z8JGBFG9E19YR</td>\n",
       "      <td>biomed</td>\n",
       "      <td>Rod spherules establish an invaginating synaps...</td>\n",
       "      <td>Rod</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>3P0I4CQYVY7RCD54ON9DS4PPT5QOWO</td>\n",
       "      <td>europarl</td>\n",
       "      <td>We have simply confirmed, in accordance with o...</td>\n",
       "      <td>Rules</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>3TFJJUELSHP4R8AUKYBF9XFJ0LWC2J</td>\n",
       "      <td>europarl</td>\n",
       "      <td>Proposal for a Council Decision establishing f...</td>\n",
       "      <td>Justice</td>\n",
       "      <td>0.203125</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>31GECDVA9JM3TSKUX9AFDA4LK3466H</td>\n",
       "      <td>europarl</td>\n",
       "      <td>The proposal to amend Regulation (EC) No 539/2...</td>\n",
       "      <td>EC</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>3OQQD2WO8I6KPTSDG8L63AI6J4E3IL</td>\n",
       "      <td>europarl</td>\n",
       "      <td>the report by Mr Albertini, on behalf of the C...</td>\n",
       "      <td>EC</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id    corpus  \\\n",
       "171  3EFNPKWBMSO9IYBXCIW0X6IAX8E030    biomed   \n",
       "252  379OL9DBSSESUVWY1Z8JGBFG9E19YR    biomed   \n",
       "280  3P0I4CQYVY7RCD54ON9DS4PPT5QOWO  europarl   \n",
       "318  3TFJJUELSHP4R8AUKYBF9XFJ0LWC2J  europarl   \n",
       "417  31GECDVA9JM3TSKUX9AFDA4LK3466H  europarl   \n",
       "418  3OQQD2WO8I6KPTSDG8L63AI6J4E3IL  europarl   \n",
       "\n",
       "                                              sentence    token  complexity  \\\n",
       "171  Lung development in Dhcr7-/- embryos at the ea...     Lung    0.175000   \n",
       "252  Rod spherules establish an invaginating synaps...      Rod    0.400000   \n",
       "280  We have simply confirmed, in accordance with o...    Rules    0.178571   \n",
       "318  Proposal for a Council Decision establishing f...  Justice    0.203125   \n",
       "417  The proposal to amend Regulation (EC) No 539/2...       EC    0.500000   \n",
       "418  the report by Mr Albertini, on behalf of the C...       EC    0.605263   \n",
       "\n",
       "     occurance_number_uncased  occurance_number_cased  \n",
       "171                         2                       1  \n",
       "252                         2                       1  \n",
       "280                         2                       1  \n",
       "318                         2                       1  \n",
       "417                         2                       1  \n",
       "418                         2                       1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(single_trial[single_trial['occurance_number_uncased']>1]))\n",
    "single_trial[single_trial['occurance_number_uncased']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Rod spherules establish an invaginating synapse with rod bipolar dendrites and axonal endings of horizontal cells.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_trial['sentence'][252]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MWE\n",
    "### train\n",
    "* 5 sentences with 2 occurances of target MWE if uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_train['occurance_number_uncased'] = multi_train.apply(lambda row:\n",
    "    row['sentence'].lower().count(row['token'].lower()), axis=1\n",
    ")\n",
    "\n",
    "multi_train['occurance_number_cased'] = multi_train.apply(lambda row:\n",
    "    row['sentence'].count(row['token']), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(multi_train['occurance_number_uncased'].unique())\n",
    "print(multi_train['occurance_number_cased'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(multi_train[multi_train['occurance_number_uncased']>1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>corpus</th>\n",
       "      <th>sentence</th>\n",
       "      <th>token</th>\n",
       "      <th>complexity</th>\n",
       "      <th>occurance_number_uncased</th>\n",
       "      <th>occurance_number_cased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>3O4VWC1GEW6GK4CJYQ66FBX6WJ5J3F</td>\n",
       "      <td>europarl</td>\n",
       "      <td>Proposal for a Council Decision establishing f...</td>\n",
       "      <td>Fundamental Rights</td>\n",
       "      <td>0.273810</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>3O4VWC1GEW6GK4CJYQ66FBX6WJ53JZ</td>\n",
       "      <td>europarl</td>\n",
       "      <td>- Madam President, the World Food Summit last ...</td>\n",
       "      <td>food security</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>30UZJB2POHC8D5XY9O2CE1E1EIA35D</td>\n",
       "      <td>europarl</td>\n",
       "      <td>Support for rural development by the European ...</td>\n",
       "      <td>rural development</td>\n",
       "      <td>0.329545</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>3AA88CN98P3CBRFP5WZ86KTWK90YKZ</td>\n",
       "      <td>europarl</td>\n",
       "      <td>Revision of the Treaties - Transitional measur...</td>\n",
       "      <td>transitional measures</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>3G5RUKN2EC3YIWSKUXZ8ZVH95VKN94</td>\n",
       "      <td>europarl</td>\n",
       "      <td>The next item is the report by Tanja Fajon, on...</td>\n",
       "      <td>Council regulation</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  id    corpus  \\\n",
       "1110  3O4VWC1GEW6GK4CJYQ66FBX6WJ5J3F  europarl   \n",
       "1185  3O4VWC1GEW6GK4CJYQ66FBX6WJ53JZ  europarl   \n",
       "1236  30UZJB2POHC8D5XY9O2CE1E1EIA35D  europarl   \n",
       "1390  3AA88CN98P3CBRFP5WZ86KTWK90YKZ  europarl   \n",
       "1406  3G5RUKN2EC3YIWSKUXZ8ZVH95VKN94  europarl   \n",
       "\n",
       "                                               sentence  \\\n",
       "1110  Proposal for a Council Decision establishing f...   \n",
       "1185  - Madam President, the World Food Summit last ...   \n",
       "1236  Support for rural development by the European ...   \n",
       "1390  Revision of the Treaties - Transitional measur...   \n",
       "1406  The next item is the report by Tanja Fajon, on...   \n",
       "\n",
       "                      token  complexity  occurance_number_uncased  \\\n",
       "1110     Fundamental Rights    0.273810                         2   \n",
       "1185          food security    0.315789                         2   \n",
       "1236      rural development    0.329545                         2   \n",
       "1390  transitional measures    0.444444                         2   \n",
       "1406     Council regulation    0.462500                         2   \n",
       "\n",
       "      occurance_number_cased  \n",
       "1110                       1  \n",
       "1185                       1  \n",
       "1236                       1  \n",
       "1390                       1  \n",
       "1406                       1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_train[multi_train['occurance_number_uncased']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Support for rural development by the European Agricultural Fund for Rural Development (EAFRD) ('"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_train['sentence'][1236]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MWE\n",
    "### trial\n",
    "only unique occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "multi_trial['occurance_number_uncased'] = multi_trial.apply(lambda row:\n",
    "    row['sentence'].lower().count(row['token'].lower()), axis=1\n",
    ")\n",
    "\n",
    "multi_trial['occurance_number_cased'] = multi_trial.apply(lambda row:\n",
    "    row['sentence'].count(row['token']), axis=1\n",
    ")\n",
    "\n",
    "print(multi_trial['occurance_number_uncased'].unique())\n",
    "print(multi_trial['occurance_number_cased'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "## are there any words not in BERT vocab? (are there words that are segmented futher?) (YES)\n",
    "\n",
    "There are lots of tokens that are not identical to vocabulary tokens of BERT. They are segmented into subwords. That means there should be a representation based on subwords. Good news: it seems that there are no unks in subwords. Uncased model knows more tokens than the cased model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_cased = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model_cased = BertModel.from_pretrained(\"bert-base-cased\")\n",
    "#config = model.config\n",
    "\n",
    "tokenizer_uncased = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_uncased = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1310 words absent out of 3487\n",
      "There are 73 words absent out of 213\n",
      "There are 929 words absent out of 3298\n",
      "There are 50 words absent out of 212\n"
     ]
    }
   ],
   "source": [
    "def check_vocab_words(vocab, words, get_not_in_vocab=True, cased=True):\n",
    "    \n",
    "    if cased:\n",
    "        not_in_vocab = set([word for word in words if word not in vocab])\n",
    "    else:\n",
    "        words = [word.lower() for word in words]\n",
    "        not_in_vocab = set([word for word in words if word not in vocab])\n",
    "    \n",
    "    if len(not_in_vocab) == 0:\n",
    "        print(\"All tokens are in the model's vocabulary\")\n",
    "    else:\n",
    "        print(\"There are\", len(not_in_vocab), 'words absent out of', len(set(words)))\n",
    "        if get_not_in_vocab:\n",
    "            return not_in_vocab\n",
    "\n",
    "not_in_vocab_train_cased = check_vocab_words(tokenizer_cased.vocab, single_train['token'])\n",
    "not_in_vocab_trial_cased = check_vocab_words(tokenizer_cased.vocab, single_trial['token'])\n",
    "\n",
    "not_in_vocab_train_uncased = check_vocab_words(tokenizer_uncased.vocab, single_train['token'], cased=False)\n",
    "not_in_vocab_trial_uncased = check_vocab_words(tokenizer_uncased.vocab, single_trial['token'], cased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 576 MWEs not segmented into two words out of 1270\n",
      "There are 40 MWEs not segmented into two words out of 76\n",
      "There are 473 MWEs not segmented into two words out of 1263\n",
      "There are 34 MWEs not segmented into two words out of 76\n"
     ]
    }
   ],
   "source": [
    "def check_vocab_mwe(tokenizer, mwes, get_not_in_vocab=True, cased=True):\n",
    "    if cased:\n",
    "        not_in_vocab = set([word_pair for word_pair in mwes if tokenizer.tokenize(word_pair)!=word_pair.split(\" \")])\n",
    "    else:\n",
    "        mwes = [word_pair.lower() for word_pair in mwes]\n",
    "        not_in_vocab = set([word_pair for word_pair in mwes if tokenizer.tokenize(word_pair)!=word_pair.split(\" \")])\n",
    "    \n",
    "    if len(not_in_vocab) == 0:\n",
    "        print(\"All tokens are in the model's vocabulary\")\n",
    "    else:\n",
    "        print(\"There are\", len(not_in_vocab), 'MWEs not segmented into two words out of', len(set(mwes)))\n",
    "        if get_not_in_vocab:\n",
    "            return not_in_vocab\n",
    "\n",
    "not_in_vocab_train_mwe_cased = check_vocab_mwe(tokenizer_cased, multi_train['token'])\n",
    "not_in_vocab_trial_mwe_cased = check_vocab_mwe(tokenizer_cased, multi_trial['token'])\n",
    "\n",
    "not_in_vocab_train_mwe_uncased = check_vocab_mwe(tokenizer_uncased, multi_train['token'], cased=False)\n",
    "not_in_vocab_trial_mwe_uncased = check_vocab_mwe(tokenizer_uncased, multi_trial['token'], cased=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "## are there any oov subwords in oov words? (NO)\n",
    "Good news: it seems that there are no unks in subwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All subwords are in vocab\n",
      "All subwords are in vocab\n",
      "All subwords are in vocab\n",
      "All subwords are in vocab\n"
     ]
    }
   ],
   "source": [
    "def check_oovs(not_in_vocab, tokenizer):\n",
    "    contains_unk_subs = []\n",
    "    for word in not_in_vocab:\n",
    "        subwords = tokenizer.tokenize(word)\n",
    "        if '[UNK]' in subwords:\n",
    "            contains_unk_subs.append(\"_\".join(subwords))\n",
    "    if len(contains_unk_subs)>0:\n",
    "        print('There some UNKs')\n",
    "    else:\n",
    "        print('All subwords are in vocab')\n",
    "\n",
    "check_oovs(not_in_vocab_train_cased, tokenizer_cased)\n",
    "check_oovs(not_in_vocab_trial_cased, tokenizer_cased)\n",
    "check_oovs(not_in_vocab_train_uncased, tokenizer_uncased)\n",
    "check_oovs(not_in_vocab_trial_uncased, tokenizer_uncased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All subwords are in vocab\n",
      "All subwords are in vocab\n",
      "All subwords are in vocab\n",
      "All subwords are in vocab\n"
     ]
    }
   ],
   "source": [
    "check_oovs(not_in_vocab_train_mwe_cased, tokenizer_cased)\n",
    "check_oovs(not_in_vocab_trial_mwe_cased, tokenizer_cased)\n",
    "check_oovs(not_in_vocab_train_mwe_uncased, tokenizer_uncased)\n",
    "check_oovs(not_in_vocab_trial_mwe_uncased, tokenizer_uncased)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.6 64-bit ('diplomchik': conda)",
   "language": "python",
   "name": "python36664bitdiplomchikcondac9dda3a2509d43ad9b71af24f3396da7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
